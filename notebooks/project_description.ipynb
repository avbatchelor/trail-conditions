{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting trail conditions\n",
    "\n",
    "The following document is a summary of my trail conditions side project. \n",
    "\n",
    "## Contents \n",
    "* Motivation & project goals\n",
    "* Scraping the data\n",
    "* Cleaning the data using NLP \n",
    "* Exploratory analysis and visualizations \n",
    "* Key discoveries \n",
    "* What I learned \n",
    "* How to use this repository\n",
    "\n",
    "## Motivation & Project Goals\n",
    "Earlier this year, I started leading hikes in the White Mountains with the awesome MIT Outing Club.  Part of what I love about winter hiking is that you may encounter a wide variety of conditions on the trails.  You might find yourself walking in three feet of powdered snow or you might find the snow to be tightly packed-down by previous hikers. These conditions require different equipment.  In powdered snow, you'll need snowshoes to stop yourself from post-holing but snowshoes are unnecssary (and tiring) on a packed-down trail.   \n",
    "\n",
    "#insert picture of post-holing vs. packed trail \n",
    "\n",
    "#![alt text](https://github.com/avbatchelor/trail-conditions/blob/master/images/trail_example.JPG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# some test code\n",
    "for i in range(1,5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use this repository\n",
    "\n",
    "## Project Organization\n",
    "------------\n",
    "\n",
    "    ├── LICENSE\n",
    "    ├── Makefile           <- Makefile with commands like `make data` or `make train`\n",
    "    ├── README.md          <- The top-level README for developers using this project.\n",
    "    ├── data\n",
    "    │   ├── external       <- Data from third party sources.\n",
    "    │   ├── interim        <- Intermediate data that has been transformed.\n",
    "    │   ├── processed      <- The final, canonical data sets for modeling.\n",
    "    │   └── raw            <- The original, immutable data dump.\n",
    "    │\n",
    "    ├── docs               <- A default Sphinx project; see sphinx-doc.org for details\n",
    "    │\n",
    "    ├── models             <- Trained and serialized models, model predictions, or model summaries\n",
    "    │\n",
    "    ├── notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),\n",
    "    │                         the creator's initials, and a short `-` delimited description, e.g.\n",
    "    │                         `1.0-jqp-initial-data-exploration`.\n",
    "    │\n",
    "    ├── references         <- Data dictionaries, manuals, and all other explanatory materials.\n",
    "    │\n",
    "    ├── reports            <- Generated analysis as HTML, PDF, LaTeX, etc.\n",
    "    │   └── figures        <- Generated graphics and figures to be used in reporting\n",
    "    │\n",
    "    ├── requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.\n",
    "    │                         generated with `pip freeze > requirements.txt`\n",
    "    │\n",
    "    ├── src                <- Source code for use in this project.\n",
    "    │   ├── __init__.py    <- Makes src a Python module\n",
    "    │   │\n",
    "    │   ├── data           <- Scripts to download or generate data\n",
    "    │   │   └── make_dataset.py\n",
    "    │   │\n",
    "    │   ├── features       <- Scripts to turn raw data into features for modeling\n",
    "    │   │   └── build_features.py\n",
    "    │   │\n",
    "    │   ├── models         <- Scripts to train models and then use trained models to make\n",
    "    │   │   │                 predictions\n",
    "    │   │   ├── predict_model.py\n",
    "    │   │   └── train_model.py\n",
    "    │   │\n",
    "    │   └── visualization  <- Scripts to create exploratory and results oriented visualizations\n",
    "    │       └── visualize.py\n",
    "    │\n",
    "    └── tox.ini            <- tox file with settings for running tox; see tox.testrun.org\n",
    "\n",
    "\n",
    "--------\n",
    "\n",
    "<p><small>Project organization based on the <a target=\"_blank\" href=\"https://drivendata.github.io/cookiecutter-data-science/\">cookiecutter data science project template</a>. #cookiecutterdatascience</small></p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
